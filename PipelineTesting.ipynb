{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"X\":[1,2,3,4,5], 'y':[10,20,30,40,50]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Pipeline\n",
    "https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines\n",
    "\n",
    "### Create Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class multiplier(BaseEstimator,TransformerMixin):\n",
    "    \"Multiply by Key\"\n",
    "    def __init__(self,weight):\n",
    "        self.weight = weight\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X*self.weight\n",
    "    \n",
    "class divider(BaseEstimator,TransformerMixin):\n",
    "    \"divide by Key\"\n",
    "    def __init__(self,divisor):\n",
    "        self.divisor = divisor\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X/self.divisor\n",
    "\n",
    "\n",
    "class concat(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"concat sentence\"\"\"\n",
    "    def __init__(self,sentence):\n",
    "        self.sentence = sentence\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.apply(lambda x: [self.sentence + str(i) for i in x])\n",
    "    \n",
    "    \n",
    "class proper(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"proper caser\"\"\"\n",
    "#     def __init__(self,sentence):\n",
    "#         self.sentence = sentence\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.apply(lambda x: [str(i).title() for i in x])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Custom Algo\n",
    "\n",
    "http://danielhnyk.cz/creating-your-own-estimator-scikit-learn/\n",
    "\n",
    "https://stackoverflow.com/questions/49017257/custom-scoring-on-gridsearchcv-with-fold-dependent-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "class CustAlgo(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"An example of classifier\"\"\"\n",
    "\n",
    "    def __init__(self, intValue=0, stringParam=\"defaultValue\", otherParam=None):\n",
    "        \"\"\"\n",
    "        Called when initializing the classifier\n",
    "        \"\"\"\n",
    "        self.intValue = intValue\n",
    "        self.stringParam = stringParam\n",
    "\n",
    "        # THIS IS WRONG! Parameters should have same name as attributes\n",
    "        self.differentParam = otherParam \n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        This should fit classifier. All the \"work\" should be done here.\n",
    "\n",
    "        Note: assert is not a good choice here and you should rather\n",
    "        use try/except blog with exceptions. This is just for short syntax.\n",
    "        \"\"\"\n",
    "\n",
    "        assert (type(self.intValue) == int), \"intValue parameter must be integer\"\n",
    "        assert (type(self.stringParam) == str), \"stringValue parameter must be string\"\n",
    "        assert (len(X) == 20), \"X must be list with numerical values.\"\n",
    "\n",
    "        self.treshold_ = (sum(X)/len(X)) + self.intValue  # mean + intValue\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _meaning(self, x):\n",
    "        # returns True/False according to fitted classifier\n",
    "        # notice underscore on the beginning\n",
    "        return( True if x >= self.treshold_ else False )\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"treshold_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        return([self._meaning(x) for x in X])\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        # counts number of values bigger than mean\n",
    "        return(sum(self.predict(X))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Two Pipelines\n",
    "numeric_pipe = Pipeline([('multiplier',multiplier(weight = 10)),('divider',divider(divisor = 100))])\n",
    "string_pipe = Pipeline([(\"concat\",concat(sentence='i transformed the following = ')),(\"proper\",proper())])\n",
    "\n",
    "# Union two feature Pipelines\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "feats = FeatureUnion([('Numeric', numeric_pipe), ('String', string_pipe)])\n",
    "\n",
    "# Assemble Main Pipeline with algorithm\n",
    "main_pipe = Pipeline([\n",
    "    ('features',feats),('AlgoName',CustAlgo())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Scorer\n",
    "\n",
    "https://github.com/EpistasisLab/tpot/issues/301#issuecomment-258236010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from numpy import mean\n",
    "def string_scorer(y_true,y_pred):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: now just a list ..  make ... numpy.ndarray {n_samples}\n",
    "    True class labels\n",
    "    y_pred: now just a list ..  make ... numpy.ndarray {n_samples}\n",
    "    Predicted class labels by the estimator\n",
    "\n",
    "    ** not used **\n",
    "    X_used: now just a list ..  make ... numpy.ndarray  {n_samples, n_features_used}\n",
    "    A numpy matrix containing the training and used features for the\n",
    "    `individual`'s evaluation\n",
    "\n",
    "    mean fitness: float\n",
    "    Returns a float value indicating the `individual`'s accuracy\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = [len(str(i)) for i in y_true]\n",
    "    y_pred = [len(str(i)) for i in y_pred]    \n",
    "    fitness = [y_i - y_pred_i for y_i,y_pred_i in zip(y_true,y_pred)]\n",
    "    return mean(fitness)\n",
    "\n",
    "print(\"Test:\", string_scorer(y_true = [43422,3243,432,1], y_pred = [12342,2344,343,1]))\n",
    "\n",
    "string_scorer = make_scorer(\n",
    "     string_scorer,\n",
    "     greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'features',\n",
       " 'AlgoName',\n",
       " 'features__n_jobs',\n",
       " 'features__transformer_list',\n",
       " 'features__transformer_weights',\n",
       " 'features__Numeric',\n",
       " 'features__String',\n",
       " 'features__Numeric__memory',\n",
       " 'features__Numeric__steps',\n",
       " 'features__Numeric__multiplier',\n",
       " 'features__Numeric__divider',\n",
       " 'features__Numeric__multiplier__weight',\n",
       " 'features__Numeric__divider__divisor',\n",
       " 'features__String__memory',\n",
       " 'features__String__steps',\n",
       " 'features__String__concat',\n",
       " 'features__String__proper',\n",
       " 'features__String__concat__sentence',\n",
       " 'AlgoName__intValue',\n",
       " 'AlgoName__otherParam',\n",
       " 'AlgoName__stringParam']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(main_pipe.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameters = { 'features__transformer_weights': [3214,234,324],\n",
    "                    'features__Numeric__divider__divisor': [10,20,30],\n",
    "                   'features__String__concat__sentence': [\"i transformed the following: \", \"i did: \", \"this is it: \"]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = GridSearchCV(main_pipe, hyperparameters, cv=2,scoring=string_scorer)\n",
    "# clf.fit(df['x'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
